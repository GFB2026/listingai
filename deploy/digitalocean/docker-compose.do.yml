# ──────────────────────────────────────────────────────────────────────────────
# ListingAI — DigitalOcean Compose Overlay
#
# This overlay replaces self-hosted postgres/redis/minio with DigitalOcean
# managed services and includes production hardening from docker-compose.prod.yml.
#
# Usage (from repo root):
#   docker compose -f docker/docker-compose.yml \
#                  -f deploy/digitalocean/docker-compose.do.yml \
#                  --env-file .env up -d
# ──────────────────────────────────────────────────────────────────────────────

x-logging: &default-logging
  driver: json-file
  options:
    max-size: "50m"
    max-file: "5"

services:
  # ── Disable self-hosted infrastructure ────────────────────────────────────
  # These services are replaced by DigitalOcean managed offerings.
  # Setting `profiles: [disabled]` prevents them from starting.
  postgres:
    profiles: [disabled]

  redis:
    profiles: [disabled]

  minio:
    profiles: [disabled]

  # The backup container used the local postgres — on DO we rely on
  # managed database automatic backups (7-day retention by default).
  backup:
    profiles: [disabled]

  # ── Backend (FastAPI) ────────────────────────────────────────────────────
  backend:
    restart: unless-stopped
    env_file: .env
    volumes: []
    ports: []  # Only exposed via nginx
    depends_on: {}  # No local DB/Redis dependencies
    command: uvicorn app.main:app --host 0.0.0.0 --port 8000 --workers 4
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://127.0.0.1:8000/health/live')"]
      interval: 15s
      timeout: 10s
      retries: 3
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: 1g
          cpus: "1.0"
        reservations:
          memory: 256m
    logging: *default-logging

  # ── Celery Worker ────────────────────────────────────────────────────────
  worker:
    restart: unless-stopped
    env_file: .env
    volumes: []
    depends_on: {}  # No local DB/Redis dependencies
    deploy:
      resources:
        limits:
          memory: 2g
          cpus: "1.0"
        reservations:
          memory: 512m
    logging: *default-logging

  # ── Celery Beat ──────────────────────────────────────────────────────────
  beat:
    restart: unless-stopped
    env_file: .env
    volumes: []
    depends_on: {}  # No local DB/Redis dependencies
    deploy:
      resources:
        limits:
          memory: 512m
          cpus: "0.5"
        reservations:
          memory: 128m
    logging: *default-logging

  # ── Frontend (Next.js) ──────────────────────────────────────────────────
  frontend:
    restart: unless-stopped
    volumes: []
    ports: []  # Only exposed via nginx
    command: ["node", "server.js"]
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://127.0.0.1:3000"]
      interval: 15s
      timeout: 10s
      retries: 3
      start_period: 20s
    deploy:
      resources:
        limits:
          memory: 512m
          cpus: "0.5"
        reservations:
          memory: 128m
    logging: *default-logging

  # ── Nginx (reverse proxy + TLS termination) ────────────────────────────
  nginx:
    image: nginx:1.27-alpine
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ../docker/nginx/nginx.conf:/etc/nginx/conf.d/default.conf:ro
      - nginx-ssl:/etc/nginx/ssl:ro
      - certbot-webroot:/var/www/certbot:ro
    depends_on:
      backend:
        condition: service_healthy
      frontend:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost/health/live"]
      interval: 15s
      timeout: 5s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 128m
          cpus: "0.25"
    logging: *default-logging

  # ── Certbot (automated TLS renewal) ────────────────────────────────────
  certbot:
    image: certbot/certbot:latest
    restart: unless-stopped
    volumes:
      - nginx-ssl:/etc/letsencrypt
      - certbot-webroot:/var/www/certbot
    entrypoint: "/bin/sh -c 'trap exit TERM; while :; do certbot renew --webroot -w /var/www/certbot --quiet; sleep 12h & wait $${!}; done;'"
    logging: *default-logging

  # ── Prometheus ──────────────────────────────────────────────────────────
  prometheus:
    image: prom/prometheus:v2.51.0
    restart: unless-stopped
    volumes:
      - ../docker/monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ../docker/monitoring/alerts.yml:/etc/prometheus/alerts.yml:ro
      - prometheus-data:/prometheus
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
      - "--storage.tsdb.retention.time=30d"
      - "--storage.tsdb.retention.size=5GB"
    depends_on:
      backend:
        condition: service_healthy
    deploy:
      resources:
        limits:
          memory: 512m
          cpus: "0.5"
    logging: *default-logging

  # ── Grafana ─────────────────────────────────────────────────────────────
  grafana:
    image: grafana/grafana:11.4.0
    restart: unless-stopped
    environment:
      GF_SECURITY_ADMIN_USER: ${GRAFANA_ADMIN_USER:-admin}
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_ADMIN_PASSWORD:-changeme}
      GF_USERS_ALLOW_SIGN_UP: "false"
    volumes:
      - grafana-data:/var/lib/grafana
      - ../docker/monitoring/grafana/provisioning:/etc/grafana/provisioning:ro
      - ../docker/monitoring/grafana/dashboards:/var/lib/grafana/dashboards:ro
    depends_on:
      - prometheus
    deploy:
      resources:
        limits:
          memory: 256m
          cpus: "0.25"
    logging: *default-logging

volumes:
  nginx-ssl:
  certbot-webroot:
  prometheus-data:
  grafana-data:
