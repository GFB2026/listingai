x-logging: &default-logging
  driver: json-file
  options:
    max-size: "50m"
    max-file: "5"

services:
  postgres:
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U listingai"]
      interval: 5s
      timeout: 5s
      retries: 5
    logging: *default-logging

  redis:
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 5s
      retries: 5
    logging: *default-logging

  minio:
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "mc", "ready", "local"]
      interval: 10s
      timeout: 5s
      retries: 3
    logging: *default-logging

  backend:
    restart: unless-stopped
    env_file: ../.env
    volumes: []
    command: uvicorn app.main:app --host 0.0.0.0 --port 8000 --workers 4
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8000/health/ready')"]
      interval: 15s
      timeout: 10s
      retries: 3
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: 1g
          cpus: "1.0"
        reservations:
          memory: 256m
    logging: *default-logging

  worker:
    restart: unless-stopped
    env_file: ../.env
    volumes: []
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    deploy:
      resources:
        limits:
          memory: 2g
          cpus: "1.0"
        reservations:
          memory: 512m
    logging: *default-logging

  beat:
    restart: unless-stopped
    env_file: ../.env
    volumes: []
    depends_on:
      redis:
        condition: service_healthy
    deploy:
      resources:
        limits:
          memory: 512m
          cpus: "0.5"
        reservations:
          memory: 128m
    logging: *default-logging

  frontend:
    restart: unless-stopped
    volumes: []
    command: ["node", "server.js"]
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:3000"]
      interval: 15s
      timeout: 10s
      retries: 3
      start_period: 20s
    deploy:
      resources:
        limits:
          memory: 512m
          cpus: "0.5"
        reservations:
          memory: 128m
    logging: *default-logging

  nginx:
    image: nginx:1.27-alpine
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/conf.d/default.conf:ro
      - nginx-ssl:/etc/nginx/ssl:ro
      - certbot-webroot:/var/www/certbot:ro
    depends_on:
      backend:
        condition: service_healthy
      frontend:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost/health/live"]
      interval: 15s
      timeout: 5s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 128m
          cpus: "0.25"
    logging: *default-logging

  # Automated TLS certificate renewal
  certbot:
    image: certbot/certbot:latest
    volumes:
      - nginx-ssl:/etc/letsencrypt
      - certbot-webroot:/var/www/certbot
    entrypoint: "/bin/sh -c 'trap exit TERM; while :; do certbot renew --webroot -w /var/www/certbot --quiet; sleep 12h & wait $${!}; done;'"
    logging: *default-logging

  # Database backup (daily pg_dump with 7-day rotation)
  backup:
    image: postgres:16-alpine
    restart: unless-stopped
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      PGHOST: postgres
      PGUSER: listingai
      PGPASSWORD: ${POSTGRES_PASSWORD}
      PGDATABASE: listingai
    volumes:
      - backups:/backups
      - ./scripts/backup.sh:/backup.sh:ro
    entrypoint: "/bin/sh -c 'chmod +x /backup.sh && while true; do /backup.sh; sleep 86400; done'"
    deploy:
      resources:
        limits:
          memory: 256m
          cpus: "0.25"
    logging: *default-logging

  # Prometheus metrics collection
  prometheus:
    image: prom/prometheus:v2.51.0
    restart: unless-stopped
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./monitoring/alerts.yml:/etc/prometheus/alerts.yml:ro
      - prometheus-data:/prometheus
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
      - "--storage.tsdb.retention.time=30d"
      - "--storage.tsdb.retention.size=5GB"
    depends_on:
      backend:
        condition: service_healthy
    deploy:
      resources:
        limits:
          memory: 512m
          cpus: "0.5"
    logging: *default-logging

  # Grafana dashboards
  grafana:
    image: grafana/grafana:11.4.0
    restart: unless-stopped
    environment:
      GF_SECURITY_ADMIN_USER: ${GRAFANA_ADMIN_USER:-admin}
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_ADMIN_PASSWORD:-changeme}
      GF_USERS_ALLOW_SIGN_UP: "false"
    volumes:
      - grafana-data:/var/lib/grafana
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning:ro
      - ./monitoring/grafana/dashboards:/var/lib/grafana/dashboards:ro
    depends_on:
      - prometheus
    deploy:
      resources:
        limits:
          memory: 256m
          cpus: "0.25"
    logging: *default-logging

volumes:
  nginx-ssl:
  certbot-webroot:
  backups:
  prometheus-data:
  grafana-data:
